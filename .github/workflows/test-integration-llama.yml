name: Integration Tests - Llama

on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]
  schedule:
    # Run daily at 3:30 AM UTC
    - cron: '30 3 * * *'
  workflow_dispatch:

permissions:
  contents: read

jobs:
  integration-tests-llama:
    runs-on: ubuntu-latest
    if: github.event_name == 'schedule' || github.event_name == 'workflow_dispatch' || (github.event_name == 'push' && github.ref == 'refs/heads/main')
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python 3.11
      uses: actions/setup-python@v4
      with:
        python-version: "3.11"
    
    - name: Install system dependencies
      run: |
        sudo apt-get update
        sudo apt-get install -y libpoppler-cpp-dev tesseract-ocr curl
    
    - name: Install Python dependencies
      run: |
        python -m pip install --upgrade pip
        pip install pytest pytest-asyncio pytest-cov
        pip install -r requirements.txt
        pip install -e .
    
    - name: Start ChromaDB
      run: |
        docker run -d -p 8000:8000 --name chromadb chromadb/chroma:0.4.15
        sleep 10
    
    - name: Install Ollama
      run: |
        curl -fsSL https://ollama.ai/install.sh | sh
        # Start Ollama in background
        ollama serve &
        sleep 10
    
    - name: Pull Llama models
      run: |
        # Pull smaller models for faster testing
        ollama pull llama3.2:1b
        ollama pull llama3.2:3b
        # Wait for models to be ready
        sleep 30
    
    - name: Verify Ollama is running
      run: |
        curl -s http://localhost:11434/api/tags | jq '.'
    
    - name: Run integration tests with Llama
      env:
        LLM_PROVIDER: llama
        OLLAMA_BASE_URL: http://localhost:11434
        LLAMA_EMBEDDING_MODEL: llama3.2:1b
        LLAMA_GENERATION_MODEL: llama3.2:3b
        CHROMA_DB_HOST: localhost
        CHROMA_DB_PORT: 8000
        CHROMA_DB_USE_REMOTE: true
        LOG_LEVEL: INFO
        LOG_FORMAT: text
      run: |
        pytest tests/integration/ -v --cov=testteller --cov-report=xml -m "integration and not slow" -k "llama or (not (gemini or openai or claude))"
    
    - name: Run CLI tests with Llama
      env:
        LLM_PROVIDER: llama
        OLLAMA_BASE_URL: http://localhost:11434
        LLAMA_EMBEDDING_MODEL: llama3.2:1b
        LLAMA_GENERATION_MODEL: llama3.2:3b
        CHROMA_DB_HOST: localhost
        CHROMA_DB_PORT: 8000
        CHROMA_DB_USE_REMOTE: true
        LOG_LEVEL: INFO
        LOG_FORMAT: text
      run: |
        pytest tests/cli/ -v -m "cli and not slow"
    
    - name: Stop services
      if: always()
      run: |
        # Stop Ollama
        pkill -f ollama || true
        # Stop ChromaDB
        docker stop chromadb || true
        docker rm chromadb || true
    
    - name: Upload coverage to Codecov
      uses: codecov/codecov-action@v3
      with:
        file: ./coverage.xml
        flags: integration-llama
        name: integration-tests-llama
        fail_ci_if_error: false 